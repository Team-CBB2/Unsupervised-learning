{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <a id=\"one\"></a>\n## 1. Importing Packages\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Importing Packages ⚡ |\n| :--------------------------- |\n| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. First we need to load the libraries we are going to use throughout our notebook. After which we will load our train and test data under loading data.|\n\n---","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:45:26.678442Z","iopub.execute_input":"2022-07-20T08:45:26.678867Z","iopub.status.idle":"2022-07-20T08:45:26.684786Z","shell.execute_reply.started":"2022-07-20T08:45:26.678836Z","shell.execute_reply":"2022-07-20T08:45:26.683413Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#pip install plotly","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:45:48.140785Z","iopub.execute_input":"2022-07-20T08:45:48.141209Z","iopub.status.idle":"2022-07-20T08:45:48.146621Z","shell.execute_reply.started":"2022-07-20T08:45:48.141164Z","shell.execute_reply":"2022-07-20T08:45:48.145397Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import scipy as sp # <-- The sister of Numpy, used in our code for numerical efficientcy. \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Entity featurization and similarity computation\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Libraries used during sorting procedures.\nimport operator # <-- Convienient item retrieval during iteration \nimport heapq # <-- Efficient sorting of large lists\n\n# Imported for our sanity\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom pandas import MultiIndex\n\nfrom plotly import graph_objects as go\n# set plot style\nimport seaborn as sns\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:45:49.588366Z","iopub.execute_input":"2022-07-20T08:45:49.589128Z","iopub.status.idle":"2022-07-20T08:45:50.391756Z","shell.execute_reply.started":"2022-07-20T08:45:49.589073Z","shell.execute_reply":"2022-07-20T08:45:50.390791Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# <a id=\"two\"></a>\n## 2. Loading the Data\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Loading the data ⚡ |\n| :--------------------------- |\n| In this section we load the data from the `train csv` file into a DataFrame for Train Data and `test_with_no_labels` file into a DataFrame for Test Data. We will be using Pandas python package to read the csv file from our local computer. We will assign our Train data to name Train and Test Data to Test. |\n\n---","metadata":{}},{"cell_type":"code","source":"#Load the tweet dataset into a dataframe\n\n\ntrain = pd.read_csv('../input/database/train.csv')\ntest = pd.read_csv('../input/database/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:45:52.667280Z","iopub.execute_input":"2022-07-20T08:45:52.667949Z","iopub.status.idle":"2022-07-20T08:46:01.239220Z","shell.execute_reply.started":"2022-07-20T08:45:52.667912Z","shell.execute_reply":"2022-07-20T08:46:01.234933Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"moviesfile = pd.read_csv('../input/database/movies.csv')\ntags = pd.read_csv('../input/database/tags.csv')\nimdb = pd.read_csv('../input/database/imdb_data.csv')\ngenome_tags = pd.read_csv('../input/database/genome_tags.csv')\ngenome_scores = pd.read_csv('../input/database/genome_scores.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:02.416424Z","iopub.execute_input":"2022-07-20T08:46:02.416802Z","iopub.status.idle":"2022-07-20T08:46:15.583201Z","shell.execute_reply.started":"2022-07-20T08:46:02.416772Z","shell.execute_reply":"2022-07-20T08:46:15.581382Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# <a id=\"three\"></a>\n## 3. Exploratory Data Analysis (EDA)\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n⚡ Description: Exploratory data analysis ⚡ |\n:--------------------------- |\nIn this section, we are required to perform an in-depth analysis of all the variables in the DataFrame. |\nwe first begin with the vital component which is the EDA, to better understand the dataset we are working with and to gain insight about the features and labels by performing Univariate or Multivariate , Non-graphical or Graphical Analysis\"\n\n\n","metadata":{}},{"cell_type":"code","source":"# Loading and displaying an overview of the data\nprint('Dimension of train is: ', train.shape)\nprint('Dimension of test is: ', test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:19.693480Z","iopub.execute_input":"2022-07-20T08:46:19.693917Z","iopub.status.idle":"2022-07-20T08:46:19.702350Z","shell.execute_reply.started":"2022-07-20T08:46:19.693886Z","shell.execute_reply":"2022-07-20T08:46:19.701106Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print (f'Number of ratings in dataset: {train.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:20.872791Z","iopub.execute_input":"2022-07-20T08:46:20.873606Z","iopub.status.idle":"2022-07-20T08:46:20.880529Z","shell.execute_reply.started":"2022-07-20T08:46:20.873554Z","shell.execute_reply":"2022-07-20T08:46:20.879355Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Let's take a look at our data","metadata":{}},{"cell_type":"code","source":"#The first ten rows of the trainig dataset\ntrain.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:21.775116Z","iopub.execute_input":"2022-07-20T08:46:21.776135Z","iopub.status.idle":"2022-07-20T08:46:21.808098Z","shell.execute_reply.started":"2022-07-20T08:46:21.776089Z","shell.execute_reply":"2022-07-20T08:46:21.806939Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After taking a look at the frist ten rows of the dataframe we can see that we have Four (4) columns in the dataFrame The test dataFrame contains only the features.\n\nWe have two features and one label features inludes:\n\n- userId\n- movieId\n- timestamp\n\nlabel:\n\n- rating","metadata":{}},{"cell_type":"markdown","source":"Now let's take a look at the data types in the dataframe using pd.info() to get more information about the dataframe","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:24.665629Z","iopub.execute_input":"2022-07-20T08:46:24.666002Z","iopub.status.idle":"2022-07-20T08:46:24.697793Z","shell.execute_reply.started":"2022-07-20T08:46:24.665972Z","shell.execute_reply":"2022-07-20T08:46:24.696278Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:25.250420Z","iopub.execute_input":"2022-07-20T08:46:25.251457Z","iopub.status.idle":"2022-07-20T08:46:27.050084Z","shell.execute_reply.started":"2022-07-20T08:46:25.251416Z","shell.execute_reply":"2022-07-20T08:46:27.048776Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"moviesfile.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:27.051887Z","iopub.execute_input":"2022-07-20T08:46:27.052218Z","iopub.status.idle":"2022-07-20T08:46:27.071154Z","shell.execute_reply.started":"2022-07-20T08:46:27.052189Z","shell.execute_reply":"2022-07-20T08:46:27.069877Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tags.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:27.073318Z","iopub.execute_input":"2022-07-20T08:46:27.074106Z","iopub.status.idle":"2022-07-20T08:46:27.177603Z","shell.execute_reply.started":"2022-07-20T08:46:27.074056Z","shell.execute_reply":"2022-07-20T08:46:27.176216Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#checking null values in the training data\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:27.669147Z","iopub.execute_input":"2022-07-20T08:46:27.669938Z","iopub.status.idle":"2022-07-20T08:46:27.740898Z","shell.execute_reply.started":"2022-07-20T08:46:27.669891Z","shell.execute_reply":"2022-07-20T08:46:27.739867Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Our training data shows that we have 0 null values which means we don't have any missing values.","metadata":{}},{"cell_type":"code","source":"moviesfile.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:29.001492Z","iopub.execute_input":"2022-07-20T08:46:29.001857Z","iopub.status.idle":"2022-07-20T08:46:29.025422Z","shell.execute_reply.started":"2022-07-20T08:46:29.001828Z","shell.execute_reply":"2022-07-20T08:46:29.024213Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tags.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:29.413653Z","iopub.execute_input":"2022-07-20T08:46:29.414038Z","iopub.status.idle":"2022-07-20T08:46:29.548818Z","shell.execute_reply.started":"2022-07-20T08:46:29.414009Z","shell.execute_reply":"2022-07-20T08:46:29.547564Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tags.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:29.869514Z","iopub.execute_input":"2022-07-20T08:46:29.870220Z","iopub.status.idle":"2022-07-20T08:46:30.069662Z","shell.execute_reply.started":"2022-07-20T08:46:29.870174Z","shell.execute_reply":"2022-07-20T08:46:30.068347Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# look at data statistics\ntrain.columns","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:30.560780Z","iopub.execute_input":"2022-07-20T08:46:30.561153Z","iopub.status.idle":"2022-07-20T08:46:30.569066Z","shell.execute_reply.started":"2022-07-20T08:46:30.561122Z","shell.execute_reply":"2022-07-20T08:46:30.567611Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Checking for unique values sentiment\ntrain['rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:31.269294Z","iopub.execute_input":"2022-07-20T08:46:31.269694Z","iopub.status.idle":"2022-07-20T08:46:31.383663Z","shell.execute_reply.started":"2022-07-20T08:46:31.269663Z","shell.execute_reply":"2022-07-20T08:46:31.382845Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":" # hostogram of total_bills\nplt.hist(train['rating'])\n  \nplt.title(\"Histogram\")\n  \n# Adding the legends\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:32.062358Z","iopub.execute_input":"2022-07-20T08:46:32.062872Z","iopub.status.idle":"2022-07-20T08:46:32.636401Z","shell.execute_reply.started":"2022-07-20T08:46:32.062828Z","shell.execute_reply":"2022-07-20T08:46:32.635155Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"table = pd.merge(train,moviesfile, on = 'movieId', how = 'outer')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:32.808901Z","iopub.execute_input":"2022-07-20T08:46:32.810094Z","iopub.status.idle":"2022-07-20T08:46:35.694072Z","shell.execute_reply.started":"2022-07-20T08:46:32.810034Z","shell.execute_reply":"2022-07-20T08:46:35.693025Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"with sns.axes_style('white'):\n    g = sns.factorplot(\"rating\", data=table, aspect=2.0,kind='count')\n    g.set_ylabels(\"Total number of ratings\")\nprint (f'Average rating in dataset: {np.mean(table[\"rating\"])}')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:35.696843Z","iopub.execute_input":"2022-07-20T08:46:35.697347Z","iopub.status.idle":"2022-07-20T08:46:45.129217Z","shell.execute_reply.started":"2022-07-20T08:46:35.697285Z","shell.execute_reply":"2022-07-20T08:46:45.127830Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# <a id=\"four\"></a>\n## 4. Data Engineering\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n|⚡ Description: Data engineering ⚡ |\n|:--------------------------- |\n| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase our datasets contains a non_numerical column certain preprocessing steps must be carried out, which involves:\n\n\n#### Data processing\n\n\n","metadata":{}},{"cell_type":"code","source":"# Loading and displaying an overview of the data\nprint('Dimension of train is: ', train.shape)\nprint('Dimension of test is: ', test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:45.131693Z","iopub.execute_input":"2022-07-20T08:46:45.132713Z","iopub.status.idle":"2022-07-20T08:46:45.139989Z","shell.execute_reply.started":"2022-07-20T08:46:45.132662Z","shell.execute_reply":"2022-07-20T08:46:45.138412Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"1. There are 4 columns and 10000038 rows for the Train Data.\n2. There are 2 columns and 5000019 for the Test Data.","metadata":{}},{"cell_type":"markdown","source":"A look at the first ten rows of our data","metadata":{}},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:48.721727Z","iopub.execute_input":"2022-07-20T08:46:48.722168Z","iopub.status.idle":"2022-07-20T08:46:48.735302Z","shell.execute_reply.started":"2022-07-20T08:46:48.722133Z","shell.execute_reply":"2022-07-20T08:46:48.734060Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"moviesfile.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:50.537707Z","iopub.execute_input":"2022-07-20T08:46:50.538651Z","iopub.status.idle":"2022-07-20T08:46:50.550522Z","shell.execute_reply.started":"2022-07-20T08:46:50.538602Z","shell.execute_reply":"2022-07-20T08:46:50.549589Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tags.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:54.302857Z","iopub.execute_input":"2022-07-20T08:46:54.303784Z","iopub.status.idle":"2022-07-20T08:46:54.316746Z","shell.execute_reply.started":"2022-07-20T08:46:54.303739Z","shell.execute_reply":"2022-07-20T08:46:54.315335Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"table.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:54.695534Z","iopub.execute_input":"2022-07-20T08:46:54.696749Z","iopub.status.idle":"2022-07-20T08:46:54.713931Z","shell.execute_reply.started":"2022-07-20T08:46:54.696685Z","shell.execute_reply":"2022-07-20T08:46:54.712770Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print (f'Number of ratings in dataset: {table.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:56.018052Z","iopub.execute_input":"2022-07-20T08:46:56.018502Z","iopub.status.idle":"2022-07-20T08:46:56.024757Z","shell.execute_reply.started":"2022-07-20T08:46:56.018464Z","shell.execute_reply":"2022-07-20T08:46:56.023836Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# <a id=\"five\"></a>\n## 5. Modelling\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n|⚡ Description: Modelling on the movie recommendations system ⚡ |\n|:--------------------------- |\n\n\n\n#### Train - Test - Split\n\nBefore anything we have to split our train data into features and target variables. Split our train data into a train and validation set. This will allow us to evaluate our model performance and chose the best model to use for our submission\n\n---","metadata":{}},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:46:59.633512Z","iopub.execute_input":"2022-07-20T08:46:59.634647Z","iopub.status.idle":"2022-07-20T08:46:59.648029Z","shell.execute_reply.started":"2022-07-20T08:46:59.634592Z","shell.execute_reply":"2022-07-20T08:46:59.646236Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"moviesfile.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:47:00.849032Z","iopub.execute_input":"2022-07-20T08:47:00.850740Z","iopub.status.idle":"2022-07-20T08:47:00.865774Z","shell.execute_reply.started":"2022-07-20T08:47:00.850665Z","shell.execute_reply":"2022-07-20T08:47:00.864268Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"tags.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:47:05.305904Z","iopub.execute_input":"2022-07-20T08:47:05.306451Z","iopub.status.idle":"2022-07-20T08:47:05.317854Z","shell.execute_reply.started":"2022-07-20T08:47:05.306403Z","shell.execute_reply":"2022-07-20T08:47:05.316852Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"table.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:47:06.561857Z","iopub.execute_input":"2022-07-20T08:47:06.562902Z","iopub.status.idle":"2022-07-20T08:47:06.580104Z","shell.execute_reply.started":"2022-07-20T08:47:06.562859Z","shell.execute_reply":"2022-07-20T08:47:06.578749Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:47:10.575124Z","iopub.execute_input":"2022-07-20T08:47:10.575971Z","iopub.status.idle":"2022-07-20T08:47:10.580419Z","shell.execute_reply.started":"2022-07-20T08:47:10.575925Z","shell.execute_reply":"2022-07-20T08:47:10.579288Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"table['auth_tags'] = (pd.Series(table[[ 'genres']]\n                      .fillna('')\n                      .values.tolist()).str.join(' '))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:52:13.364615Z","iopub.execute_input":"2022-07-20T08:52:13.365057Z","iopub.status.idle":"2022-07-20T08:52:32.621188Z","shell.execute_reply.started":"2022-07-20T08:52:13.365022Z","shell.execute_reply":"2022-07-20T08:52:32.619776Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Convienient indexes to map between our movie titles and indexes of \n# the movies dataframe\ntitles = table['title']\nindices = pd.Series(table.index, index=table['title'])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:52:36.352263Z","iopub.execute_input":"2022-07-20T08:52:36.352692Z","iopub.status.idle":"2022-07-20T08:52:36.807954Z","shell.execute_reply.started":"2022-07-20T08:52:36.352657Z","shell.execute_reply":"2022-07-20T08:52:36.806771Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:52:38.270089Z","iopub.execute_input":"2022-07-20T08:52:38.270939Z","iopub.status.idle":"2022-07-20T08:52:38.276621Z","shell.execute_reply.started":"2022-07-20T08:52:38.270895Z","shell.execute_reply":"2022-07-20T08:52:38.275347Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"table.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:52:40.355059Z","iopub.execute_input":"2022-07-20T08:52:40.355863Z","iopub.status.idle":"2022-07-20T08:52:40.374021Z","shell.execute_reply.started":"2022-07-20T08:52:40.355811Z","shell.execute_reply":"2022-07-20T08:52:40.373202Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"from scipy import spatial\nfrom sklearn.metrics.pairwise import cosine_similarity,cosine_distances","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:33:27.315313Z","iopub.execute_input":"2022-07-20T11:33:27.315628Z","iopub.status.idle":"2022-07-20T11:33:27.320948Z","shell.execute_reply.started":"2022-07-20T11:33:27.315600Z","shell.execute_reply":"2022-07-20T11:33:27.319841Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2),\n                     min_df=0, stop_words='english')\n\n# Produce a feature matrix, where each row corresponds to a movie,\n# with TF-IDF features as columns \ntf_authTags_matrix = tf.fit_transform(table['auth_tags'])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:33:29.392160Z","iopub.execute_input":"2022-07-20T11:33:29.392545Z","iopub.status.idle":"2022-07-20T11:33:29.411399Z","shell.execute_reply.started":"2022-07-20T11:33:29.392517Z","shell.execute_reply":"2022-07-20T11:33:29.409902Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n\ncosine_sim_authTags = cosine_similarity(tf_authTags_matrix,\n                                        tf_authTags_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:33:15.228986Z","iopub.execute_input":"2022-07-20T11:33:15.229291Z","iopub.status.idle":"2022-07-20T11:33:15.680160Z","shell.execute_reply.started":"2022-07-20T11:33:15.229268Z","shell.execute_reply":"2022-07-20T11:33:15.678945Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cosine_sim_authTags = cosine_similarity(tf_authTags_matrix,\n                                        tf_authTags_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:33:11.926077Z","iopub.execute_input":"2022-07-20T11:33:11.926406Z","iopub.status.idle":"2022-07-20T11:33:11.939173Z","shell.execute_reply.started":"2022-07-20T11:33:11.926382Z","shell.execute_reply":"2022-07-20T11:33:11.937904Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"cosine_sim_authTags[:5]","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:32:56.316427Z","iopub.execute_input":"2022-07-20T11:32:56.316954Z","iopub.status.idle":"2022-07-20T11:32:56.394060Z","shell.execute_reply.started":"2022-07-20T11:32:56.316851Z","shell.execute_reply":"2022-07-20T11:32:56.392711Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Recommendations","metadata":{}},{"cell_type":"code","source":"def content_generate_rating_estimate(movie_title, user, rating_data, k=20, threshold=0.0):\n    # Convert the book title to a numeric index for our \n    # similarity matrix\n    b_idx = indices[movie_title]\n    neighbors = [] # <-- Stores our collection of similarity values \n\n    # Gather the similarity ratings between each movie the user has rated\n    # and the reference book \n    for index, row in rating_data[rating_data['userId']==user].iterrows():\n        sim = cosine_sim_authTags[b_idx-1, indices[row['title']]-1]\n        neighbors.append((sim, row['rating']))\n    # Select the top-N values from our collection\n    k_neighbors = heapq.nlargest(k, neighbors, key=lambda t: t[0])\n\n    # Compute the weighted average using similarity scores and \n    # user item ratings. \n    simTotal, weightedSum = 0, 0\n    for (simScore, rating) in k_neighbors:\n        # Ensure that similarity ratings are above a given threshold\n        if (simScore > threshold):\n            simTotal += simScore\n            weightedSum += simScore * rating\n    try:\n        predictedRating = weightedSum / simTotal\n    except ZeroDivisionError:\n        # Cold-start problem - No ratings given by user. \n        # We use the average rating for the reference item as a proxy in this case \n        predictedRating = np.mean(rating_data[rating_data['title']==movie_title]['rating'])\n    return predictedRating","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:26:35.085666Z","iopub.execute_input":"2022-07-20T08:26:35.086120Z","iopub.status.idle":"2022-07-20T08:26:35.095599Z","shell.execute_reply.started":"2022-07-20T08:26:35.086080Z","shell.execute_reply":"2022-07-20T08:26:35.094720Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Subset of ratings from user 314\ntable[table['userId'] == 314][3:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:25:29.757419Z","iopub.execute_input":"2022-07-20T12:25:29.757712Z","iopub.status.idle":"2022-07-20T12:25:29.770955Z","shell.execute_reply.started":"2022-07-20T12:25:29.757689Z","shell.execute_reply":"2022-07-20T12:25:29.769793Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"title = \"Three Musketeers, The (1993)\"\nactual_rating = table[(table['userId'] == 314) & (table['title'] == title)]['rating'].values[0]\npred_rating = content_generate_rating_estimate(movie_title=title, user=314, rating_data=table)\nprint (f\"Title - {title}\")\nprint (\"---\")\nprint (f\"Actual rating: \\t\\t {actual_rating}\")\nprint (f\"Predicted rating: \\t {pred_rating}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:25:35.694408Z","iopub.execute_input":"2022-07-20T12:25:35.694924Z","iopub.status.idle":"2022-07-20T12:25:35.710360Z","shell.execute_reply.started":"2022-07-20T12:25:35.694890Z","shell.execute_reply":"2022-07-20T12:25:35.709142Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}